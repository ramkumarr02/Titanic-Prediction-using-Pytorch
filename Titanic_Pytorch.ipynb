{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramkumarr02/Titanic-Prediction-using-Pytorch/blob/master/Titanic_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkbuT7q-y89U",
        "colab_type": "text"
      },
      "source": [
        "# Env Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn2wF7ZNPLN_",
        "colab_type": "text"
      },
      "source": [
        "## Packages\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjyW1FMoqlDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJRZM7glP26m",
        "colab_type": "text"
      },
      "source": [
        "## Mount Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5Wwbddv5ydr",
        "colab_type": "code",
        "outputId": "14980499-1b39-4f6d-ec1e-4bca2fc4e9be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzCE8YxPWDFW",
        "colab_type": "text"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJgbBTOeWH6u",
        "colab_type": "text"
      },
      "source": [
        "## Split Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmfDaKfWD2-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def column_split(df):\n",
        "\n",
        "    try:\n",
        "        df['SurName'], df['Name'] = df['Name'].str.split(',', 1).str\n",
        "        df['Title'], df['Name'] = df['Name'].str.split('.', 1).str\n",
        "        df['Cabin_Section'] = df[df['Cabin'].notna()]['Cabin'].astype(str).str[0]\n",
        "        df['Cabin_Nums'] = df[df['Cabin'].notna()]['Cabin'].str.count(\" \") + 1\n",
        "        del df['Name']\n",
        "        del df['Ticket']\n",
        "        del df['Cabin']\n",
        "        #del df['SurName']\n",
        "        \n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    return(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny-llUPnWM0N",
        "colab_type": "text"
      },
      "source": [
        "## Impute Age by title"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P38HjZPRbo1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def impute_age_by_title(df):       \n",
        "    train_with_age = df.copy()\n",
        "\n",
        "    train_with_age_notnull = train_with_age[train_with_age['Age'].notna()]\n",
        "\n",
        "    age_map = train_with_age_notnull.groupby(['Title'])['Age'].mean().astype('int').to_dict()\n",
        "    age_map[' Ms'] = 28\n",
        "\n",
        "    #temp = train_with_age['Age']\n",
        "\n",
        "    for i, row in train_with_age.iterrows():           \n",
        "        if pd.isnull(row['Age']):\n",
        "            df.Age[i] = age_map[train_with_age.Title[i]]  \n",
        "\n",
        "    return(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxpZV4kGWQKF",
        "colab_type": "text"
      },
      "source": [
        "## Change all data type into int"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmjiRLCKRIP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def change_dtype(df):\n",
        "    not_int_cols = list(df.select_dtypes(exclude=['int']).columns)\n",
        "    df[not_int_cols] = df[not_int_cols].astype('int')\n",
        "    return(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kOq_aD1WU7V",
        "colab_type": "text"
      },
      "source": [
        "## Scale Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2paQ1lZZscZH",
        "colab": {}
      },
      "source": [
        "def scale_data(df):\n",
        "\n",
        "    scaled_features = StandardScaler().fit_transform(df.values)\n",
        "    df = pd.DataFrame(scaled_features, index=df.index, columns=df.columns)\n",
        " \n",
        "    return(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gPMsZFsC9iI",
        "colab_type": "text"
      },
      "source": [
        "## PreProcess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybzyNc74C9UB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre_process(df, prep_flag = None, train_data = None):        \n",
        "\n",
        "    # Feature Engineering : Split Columns\n",
        "    df = column_split(df)\n",
        "\n",
        "    # Feature Engineering : Impute Age by Title\n",
        "    df = impute_age_by_title(df)\n",
        "\n",
        "    # One Hot Encoding\n",
        "    df = pd.get_dummies(df)\n",
        "\n",
        "    if prep_flag != None:\n",
        "        train_data, df = train_data.align(df, join='left', axis=1)\n",
        "\n",
        "    # Remove NaN\n",
        "    df = df.fillna(0)\n",
        "\n",
        "    # Change all Data types to Int\n",
        "    df = change_dtype(df)\n",
        "\n",
        "    # Scale Data\n",
        "    scaled_df = scale_data(df)\n",
        "\n",
        "    return(scaled_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltjxNNVfSY3p",
        "colab_type": "text"
      },
      "source": [
        "## PD.DF to Tensor.DF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oix0iPMNPOvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def df2df_tens(x,y):\n",
        "    tens_x = torch.FloatTensor(x.values.astype('float'))\n",
        "    tens_y = torch.LongTensor(y.values.astype('long'))\n",
        "    \n",
        "    df_tens = TensorDataset(tens_x, tens_y)    \n",
        "\n",
        "    return(df_tens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fFmRF4ROxF-",
        "colab_type": "text"
      },
      "source": [
        "## Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd9sErE2T1OY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 50)\n",
        "        self.fc2 = nn.Linear(50, 30)        \n",
        "        self.fc3 = nn.Linear(30, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)                \n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)                \n",
        "        return(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I2XOfM3wgHnM"
      },
      "source": [
        "## Model Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D-Csw2Z-gHnN",
        "colab": {}
      },
      "source": [
        "def train_model(num_epochs, optimizer, criterion, train_loader, valid_loader, n_test):\n",
        "    loss_list = []\n",
        "    accuracy_list = []  \n",
        "\n",
        "    for epoch in range(num_epochs):   \n",
        "        for x,y in train_loader:        \n",
        "            optimizer.zero_grad()\n",
        "            yhat = model(x)\n",
        "            loss =criterion(yhat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        correct = 0\n",
        "        for x_test, y_test in valid_loader:        \n",
        "            z = model(x_test)\n",
        "            _, yhat = torch.max(z.data, 1)        \n",
        "            correct += (yhat == y_test).sum().item()\n",
        "        \n",
        "        accuracy = correct/n_test        \n",
        "        accuracy_list.append(accuracy)\n",
        "        loss_list.append(loss.data)\n",
        "\n",
        "        if epoch % 2 == 0:\n",
        "            print(f'Epoch : {epoch}, Loss : {loss.data} , Accuracy : {accuracy}')        \n",
        "\n",
        "    return(model, loss_list, accuracy_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un-sEXQhWZxt",
        "colab_type": "text"
      },
      "source": [
        "# Code Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcjsnMmsMgwE",
        "colab_type": "text"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-ZBb--KMgF9",
        "colab_type": "code",
        "outputId": "aade3d70-155b-4316-feab-f175d05e4acb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Deep Learning/Titanic/PyTorch/train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Deep Learning/Titanic/PyTorch/test.csv')\n",
        "\n",
        "del train['PassengerId']\n",
        "del test['PassengerId']\n",
        "\n",
        "train_copy = train.copy()\n",
        "test_copy = test.copy()\n",
        "\n",
        "train.head(2)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Pclass  ... Cabin Embarked\n",
              "0         0       3  ...   NaN        S\n",
              "1         1       1  ...   C85        C\n",
              "\n",
              "[2 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3NYGntqqybR",
        "colab_type": "text"
      },
      "source": [
        "## Split Data for OOB testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1RFASmbjMNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.concat([train]*20, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhXDEYTyXUPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x, valid_x, train_y, valid_y = train_test_split(train.loc[:, train.columns != 'Survived'], train['Survived'],train_size = 0.8,random_state = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f2mvVRXTrjE",
        "colab_type": "text"
      },
      "source": [
        "## PreProcess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI1GzO3oCsnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaled_train_x = pre_process(train_x)\n",
        "scaled_valid_x = pre_process(valid_x, train_data = scaled_train_x, prep_flag = 'valid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upOglTkpQaO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert Dataframe to Tensor Dataframe \n",
        "train_tensor = df2df_tens(scaled_train_x,train_y)\n",
        "valid_tensor = df2df_tens(scaled_valid_x,valid_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsx5to5aoZOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Loader : Train and valid\n",
        "train_loader = DataLoader(dataset = train_tensor, batch_size=batch_size, shuffle = True)\n",
        "valid_loader = DataLoader(dataset = valid_tensor, batch_size=batch_size, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM5Qm_EKs4yS",
        "colab_type": "text"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZjO82t1O2FK",
        "colab_type": "text"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Eqp7S8uAnnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 500\n",
        "\n",
        "#input_size = 589\n",
        "input_size = 703\n",
        "output_size = 2\n",
        "num_epochs = 10\n",
        "learning_rate = 0.01\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "n_test = len(scaled_valid_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7RelEgaT1Le",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Net(input_size = input_size, output_size = output_size)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yInMNqevfyKp",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne4mvaeBe_fS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "b7d225c8-869a-49ce-c982-244544ec2c2d"
      },
      "source": [
        "model, loss_list, accuracy_list = train_model(num_epochs, optimizer, criterion, train_loader, valid_loader, n_test)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0, Loss : 0.02535015158355236 , Accuracy : 0.9910213243546577\n",
            "Epoch : 2, Loss : 0.006903147324919701 , Accuracy : 0.9935465768799102\n",
            "Epoch : 4, Loss : 0.008495423942804337 , Accuracy : 0.9941077441077442\n",
            "Epoch : 6, Loss : 0.004000845365226269 , Accuracy : 0.9971941638608305\n",
            "Epoch : 8, Loss : 0.002794662257656455 , Accuracy : 0.9980359147025814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mqho6ihcsvQg",
        "colab_type": "text"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LIUa4CoOrIXi"
      },
      "source": [
        "## Prep Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVmQ8QdkXUHn",
        "colab_type": "code",
        "outputId": "2fab6629-87cb-4953-9888-cc1f45c03437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "scaled_test_x = pre_process(test, train_data = scaled_train_x, prep_flag = 'Test')\n",
        "test_x_tens = torch.FloatTensor(scaled_test_x.values.astype('float'))\n",
        "\n",
        "z_test = model(test_x_tens)\n",
        "_, yhat = torch.max(z_test.data, 1)\n",
        "print(len(yhat))\n",
        "yhat"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "418\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "        1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "        1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
              "        1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
              "        1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
              "        1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
              "        1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
              "        1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "        0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
              "        1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
              "        1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "        0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "        0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "        0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
              "        0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
              "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    }
  ]
}